{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference\n",
    "#https://medium.com/towards-artificial-intelligence/nothing-but-numpy-understanding-creating-neural-networks-with-computational-graphs-from-scratch-6299901091b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Basic Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/img_01_nn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/towards-artificial-intelligence/nothing-but-numpy-understanding-creating-neural-networks-with-computational-graphs-from-scratch-6299901091b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "weights: Contains weight whose value neural network would learn.\n",
    "\"\"\"\n",
    "weights = np.array([0.1, 0.6])\n",
    "\n",
    "print(weights.shape)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initially set bias to Zero\n",
    "\"\"\"\n",
    "bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Just extracting input features from data points\n",
    "\"\"\"\n",
    "X_O = data[:, :2]\n",
    "print(X_O.shape)\n",
    "X_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [0, 1, 0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "As we need to perform dot product in next step, therefore to define valid dimesions\n",
    "we have to take transpose of X_O\n",
    "\"\"\"\n",
    "X = X_O.T\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracting output values corresponding to input features\n",
    "\"\"\"\n",
    "Y =  data[:, -1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1] Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0. , 0.6, 0.1, 0.7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we are doing linear computations of all examples (On example contains available all input features) in one training\n",
    "dataset simulataneously.\n",
    "\"\"\"\n",
    "Z = np.dot(weights, X)\n",
    "print(Z.shape)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigmoid(z):\n",
    "    \"\"\"\n",
    "    We are here trying to squash output to range (0, 1)\n",
    "    Note: Parenthesis implies exclusive boundary values.\n",
    "    \n",
    "    Here we input linear computation to sigmoid function and gets output range (0, 1)\n",
    "    \n",
    "    z: Linear equation.\n",
    "    For this neural network it would be\n",
    "    [\n",
    "        weight[0] * X[0][0] + weight[1] * X[1][0] + b\n",
    "        weight[0] * X[0][1] + weight[1] * X[1][1] + b\n",
    "        weight[0] * X[0][2] + weight[1] * X[1][2] + b\n",
    "        weight[0] * X[0][3] + weight[1] * X[1][3] + b\n",
    "    ]    \n",
    "    \n",
    "    sigmoid output\n",
    "    \"\"\"\n",
    "    \n",
    "    sig = np.divide(1, np.add(1, np.exp(-z)))\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y, y_hat, m, const = 2):\n",
    "    \"\"\"\n",
    "    As we're considering all example simulataneously therefore we're using\n",
    "    cost function instead loss function.\n",
    "    \n",
    "    We have to sum up all the loos due to each example and compute average.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_cost = np.sum(np.divide(np.subtract(y, y_hat) ** 2, const))\n",
    "    \n",
    "    avg_cost = np.divide(total_cost, m)\n",
    "\n",
    "    return avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_cost__by__del_y_hat(y, y_hat, m):\n",
    "    \"\"\"\n",
    "    here we'are computing gradient of cost function w.r.t y_hat\n",
    "    as we know cost function is (y - y_hat)^2 / ( 2 * m )\n",
    "    Therefore it's gardien would be\n",
    "    \n",
    "    (-1 / m)(y - y_hat)\n",
    "    \n",
    "    avg_grad: vector of m length. Each element contains loss corresponding to each example.\n",
    "    \"\"\"\n",
    "    \n",
    "    grad = -np.subtract(y, y_hat)\n",
    "    \n",
    "    avg_grad = np.divide(grad, m)\n",
    "    \n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.64565631, 0.52497919, 0.66818777])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = compute_sigmoid(Z)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08891294752305501"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cost = compute_cost(Y, y_hat, len(y_hat))\n",
    "avg_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2] Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.125     , -0.08858592, -0.1187552 , -0.08295306])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_cost = del_cost__by__del_y_hat(Y, y_hat, len(y_hat))\n",
    "grad_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_y_hat__by__del_z(y_hat):\n",
    "    \"\"\"\n",
    "        del_y_hat__by__del_z: $(y_hat)/$(z)\n",
    "            As we know\n",
    "            y_hat = sigmoid(z), therefore,\n",
    "            $(sigmoid(z)) / $(z) : sigmoid(z)[1 - sigmoid(z)] OR [y_hat * (1 - y_hat)] \n",
    "    \"\"\"\n",
    "    \n",
    "    one_sub_sigma = np.subtract(1, y_hat)\n",
    "    \n",
    "    grad = np.multiply(y_hat, one_sub_sigma)\n",
    "\n",
    "    return grad\n",
    "\n",
    "grad_y_hat__by__del_z = del_y_hat__by__del_z(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_grad_at__z(grad_cost, grad_y_hat__by__del_z):\n",
    "    \"\"\"\n",
    "    Here we're computing final gradient at Z node i.e. multiplication of\n",
    "    local gradient at Z node and incming gradient from cost\n",
    "    \n",
    "    grad_cost : Gradient of cost function\n",
    "    grad_y_hat__by__del_z: Local gradient at node Z ($y_hat/$z)\n",
    "    \n",
    "    grad_at_node__z: final gradient at node z\n",
    "    \"\"\"\n",
    "    grad_at_node__z = np.multiply(grad_cost, grad_y_hat__by__del_z)\n",
    "    \n",
    "    return grad_at_node__z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03125   , -0.02026706, -0.0296147 , -0.01839176])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_cost__by__del_z = final_grad_at__z(grad_cost, grad_y_hat__by__del_z)\n",
    "grad_cost__by__del_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_z__by__del_weight0(X):\n",
    "    \"\"\"\n",
    "    del_z__by__del_weight0 OR del_z__by__del_w0\n",
    "    \n",
    "    As we know that at Z node linear equation would be\n",
    "    [\n",
    "        weight[0] * X[0][0] + weight[1] * X[1][0] + b\n",
    "        weight[0] * X[0][1] + weight[1] * X[1][1] + b\n",
    "        weight[0] * X[0][2] + weight[1] * X[1][2] + b\n",
    "        weight[0] * X[0][3] + weight[1] * X[1][3] + b\n",
    "    ]\n",
    "    \n",
    "    Therefore it's differentiation w.r.t weight[0] would be \n",
    "        [X[0][0]        X[0][1]        X[0][2]        X[0][3]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return X[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_z__by__del_weight0 = del_z__by__del_weight0(X)\n",
    "grad_z__by__del_weight0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_z__by__del_weight1(X):\n",
    "    \"\"\"\n",
    "    del_z__by__del_weight0 OR del_z__by__del_w1\n",
    "    \n",
    "    As we know that at Z node linear equation would be\n",
    "    [\n",
    "        weight[0] * X[0][0] + weight[1] * X[1][0] + b\n",
    "        weight[0] * X[0][1] + weight[1] * X[1][1] + b\n",
    "        weight[0] * X[0][2] + weight[1] * X[1][2] + b\n",
    "        weight[0] * X[0][3] + weight[1] * X[1][3] + b\n",
    "    ]\n",
    "    \n",
    "    Therefore it's differentiation w.r.t weight[1] would be \n",
    "        [X[1][0]        X[1][1]        X[1][2]        X[1][3]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return X[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_z__by__del_weight1 = del_z__by__del_weight1(X)\n",
    "grad_z__by__del_weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_z__by__del_bias():\n",
    "    \"\"\"\n",
    "    del_z__by__del_bias OR del_z__by__del_b\n",
    "    \n",
    "    As we know that at Z node linear equation would be\n",
    "    [np.mdot(weight, X) + b]\n",
    "    \n",
    "    Therefore it's differentiation w.r.t bias would be 1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return np.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_z__by__del_bias = del_z__by__del_bias()\n",
    "grad_z__by__del_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04800646, -0.03865882])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_cost__by__del_weight = np.dot( grad_cost__by__del_z, X_O)\n",
    "grad_cost__by__del_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngrad_cost__by__del_weight0 = np.sum(np.multiply(grad_cost__by__del_z, grad_z__by__del_weight0))\\nprint(grad_cost__by__del_weight0)\\n\\ngrad_cost__by__del_weight1 = np.sum(np.multiply(grad_cost__by__del_z, grad_z__by__del_weight1))\\nprint(grad_cost__by__del_weight1)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Other way to compute :\n",
    "\n",
    "    grad_cost__by__del_weight0\n",
    "    and\n",
    "    grad_cost__by__del_weight1\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "grad_cost__by__del_weight0 = np.sum(np.multiply(grad_cost__by__del_z, grad_z__by__del_weight0))\n",
    "print(grad_cost__by__del_weight0)\n",
    "\n",
    "grad_cost__by__del_weight1 = np.sum(np.multiply(grad_cost__by__del_z, grad_z__by__del_weight1))\n",
    "print(grad_cost__by__del_weight1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3] Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04800646 -0.03865882]\n"
     ]
    }
   ],
   "source": [
    "print(grad_cost__by__del_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lr: Learning rate\n",
    "\"\"\"\n",
    "lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04800646 -0.03865882]\n"
     ]
    }
   ],
   "source": [
    "weights__lr = np.multiply(grad_cost__by__del_weight, 1)\n",
    "print(weights__lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14800646, 0.63865882])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_weights = np.subtract(weights, weights__lr)\n",
    "updated_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.4] Update bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03702352612570836"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "$cost/$b: Change in cost function w.r.t bias\n",
    "\"\"\"\n",
    "grad_cost__by__del_bias = np.sum(np.multiply( grad_cost__by__del_z, grad_z__by__del_bias))\n",
    "grad_cost__by__del_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03702352612570836"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_bias = bias - np.multiply(lr, grad_cost__by__del_bias)\n",
    "updated_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
