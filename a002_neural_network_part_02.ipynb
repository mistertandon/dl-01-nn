{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please go through this <a href=\"https://medium.com/towards-artificial-intelligence/nothing-but-numpy-understanding-creating-neural-networks-with-computational-graphs-from-scratch-6299901091b0\">brilliant artical</a> before using this jupyter notebook\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Basic Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/img_01_nn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/towards-artificial-intelligence/nothing-but-numpy-understanding-creating-neural-networks-with-computational-graphs-from-scratch-6299901091b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "weights: Contains weight whose value neural network would learn.\n",
    "\"\"\"\n",
    "weights = np.array([0.1, 0.6])\n",
    "\n",
    "print(weights.shape)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initially set bias to Zero\n",
    "\"\"\"\n",
    "bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Just extracting input features from data points\n",
    "\"\"\"\n",
    "X_O = data[:, :2]\n",
    "print(X_O.shape)\n",
    "X_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [0, 1, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "As we need to perform dot product in next step, therefore to define valid dimesions\n",
    "we have to take transpose of X_O\n",
    "\"\"\"\n",
    "X = X_O.T\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracting output values corresponding to input features\n",
    "\"\"\"\n",
    "Y =  data[:, -1]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.1] Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0. , 0.6, 0.1, 0.7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we are doing linear computations of all examples (On example contains available all input features) in one training\n",
    "dataset simulataneously.\n",
    "         \n",
    "\n",
    "Where X : array([[0, 0, 0],\n",
    "                 [0, 1, 1],\n",
    "                 [1, 0, 1],\n",
    "                 [1, 1, 1]])\n",
    "\n",
    "And\n",
    "\n",
    "weights: array([0.1, 0.6])\n",
    "\"\"\"\n",
    "Z = np.add(bias, np.dot(weights, X))\n",
    "print(Z.shape)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigmoid(z):\n",
    "    \"\"\"\n",
    "    We are here trying to squash output to range (0, 1)\n",
    "    Note: Parenthesis implies exclusive boundary values.\n",
    "    \n",
    "    Here we input linear computation to sigmoid function and gets output range (0, 1)\n",
    "    \n",
    "    z: Linear equation.\n",
    "    For this neural network it would be\n",
    "    [\n",
    "        weight[0] * X[0][0] + weight[1] * X[1][0] + b\n",
    "        weight[0] * X[0][1] + weight[1] * X[1][1] + b\n",
    "        weight[0] * X[0][2] + weight[1] * X[1][2] + b\n",
    "        weight[0] * X[0][3] + weight[1] * X[1][3] + b\n",
    "    ]    \n",
    "    \n",
    "    sigmoid output\n",
    "    \"\"\"\n",
    "    \n",
    "    sig = np.divide(1, np.add(1, np.exp(-z)))\n",
    "    \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.64565631, 0.52497919, 0.66818777])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = compute_sigmoid(Z)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(y, y_hat, m, const = 2):\n",
    "    \"\"\"\n",
    "    As we're considering all example simulataneously therefore we're using\n",
    "    cost function instead loss function.\n",
    "    \n",
    "    We have to sum up all the loos due to each example and compute average.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_cost = np.sum(np.divide(np.subtract(y, y_hat) ** 2, const))\n",
    "    \n",
    "    avg_cost = np.divide(total_cost, m)\n",
    "\n",
    "    return avg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08891294752305501"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cost = compute_cost(Y, y_hat, len(y_hat))\n",
    "avg_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2] Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute__del_cost__by__del_y_hat(y, y_hat, m):\n",
    "    \"\"\"\n",
    "    here we'are computing gradient of cost function w.r.t y_hat\n",
    "    as we know cost function is (y - y_hat)^2 / ( 2 * m )\n",
    "    Therefore it's gardien would be\n",
    "    \n",
    "    (-1 / m)(y - y_hat)\n",
    "    \n",
    "    avg_grad: vector of m length. Each element contains loss corresponding to each example.\n",
    "    \"\"\"\n",
    "    \n",
    "    grad = -np.subtract(y, y_hat)\n",
    "    \n",
    "    avg_grad = np.divide(grad, m)\n",
    "    \n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.125     , -0.08858592, -0.1187552 , -0.08295306])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local__del_cost__by__del_y_hat = compute__del_cost__by__del_y_hat(Y, y_hat, len(y_hat))\n",
    "local__del_cost__by__del_y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute__del_y_hat__by__del_z(y_hat):\n",
    "    \"\"\"\n",
    "        del_y_hat__by__del_z [$(y_hat)/$(z)] \n",
    "            As we know\n",
    "            y_hat = sigmoid(z), therefore,\n",
    "            $(sigmoid(z)) / $(z) : sigmoid(z)[1 - sigmoid(z)] OR [y_hat * (1 - y_hat)] \n",
    "    \"\"\"\n",
    "\n",
    "    one_sub_sigma = np.subtract(1, y_hat)\n",
    "    \n",
    "    grad = np.multiply(y_hat, one_sub_sigma)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.22878424, 0.24937604, 0.22171287])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Local gradient at z node of 'y_hat' w.r.t 'z'\n",
    "\"\"\"\n",
    "local__del_y_hat__by__del_z = compute__del_y_hat__by__del_z(y_hat)\n",
    "local__del_y_hat__by__del_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_grad_at__z(local__del_cost__by__del_y_hat, local__del_y_hat__by__del_z):\n",
    "    \"\"\"\n",
    "    Here we're computing final gradient at Z node i.e. multiplication of\n",
    "    local gradient at Z node and incming gradient from cost.\n",
    "    ( $cost/$y_hat * $y_hat/$z )\n",
    "    \n",
    "    local__del_cost__by__del_y_hat : Gradient of cost function i.e. ($cost/$y_hat)\n",
    "    grad_y_hat__by__del_z: Local gradient at node Z ($y_hat/$z)\n",
    "    \n",
    "    grad_at_node__z: final gradient at node z\n",
    "    \"\"\"\n",
    "    grad_at_node__z = np.multiply(local__del_cost__by__del_y_hat, local__del_y_hat__by__del_z)\n",
    "    \n",
    "    return grad_at_node__z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03125   , -0.02026706, -0.0296147 , -0.01839176])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final__del_cost__by__del_z = final_grad_at__z(local__del_cost__by__del_y_hat, local__del_y_hat__by__del_z)\n",
    "final__del_cost__by__del_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute z/$w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. w is a vector i.e. np.array([0.1, 0.6])\n",
    "\n",
    "2. We do have 4 examples in training dataset\n",
    "\n",
    "array([[0, 0],\n",
    "       [0, 1],\n",
    "       [1, 0],\n",
    "       [1, 1]])\n",
    "\n",
    "jacob__del_z__by__del_w matrix would contains\n",
    "\n",
    " __       __               __                    __               __                    __\n",
    "|           |             |                        |             |                        |\n",
    "|   $z1/$w  |             |   $z1/$w1    $z1/$w2   |             |   x[0][0]    x[0][1]   |\n",
    "|           |             |                        |             |                        |\n",
    "|   $z2/$w  |             |   $z2/$w1    $z2/$w2   |             |   x[1][0]    x[1][1]   |\n",
    "|           |    ===>     |                        |    ===>     |                        | \n",
    "|   $z3/$w  |             |   $z3/$w1    $z3/$w2   |             |   x[2][0]    x[2][1]   |\n",
    "|           |             |                        |             |                        |\n",
    "|   $z4/$w  |             |   $z4/$w1    $z4/$w2   |             |   x[3][0]    x[3][1]   |\n",
    "|__       __|             |__                    __|             |__                    __|\n",
    "\n",
    "In above matrix: \n",
    "\n",
    "    z1 = weight[0] * X[0][0] + weight[1] * X[0][1] + b\n",
    "    z2 = weight[0] * X[1][0] + weight[1] * X[1][1] + b\n",
    "    z3 = weight[0] * X[2][0] + weight[1] * X[2][1] + b\n",
    "    z4 = weight[0] * X[3][0] + weight[1] * X[3][1] + b\n",
    "    \n",
    "    AND \n",
    "    \n",
    "    w1, w2 = weights\n",
    "\"\"\"\n",
    "local__del_z__by__del_w = X_O\n",
    "local__del_z__by__del_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute__del_z__by__del_bias():\n",
    "    \"\"\"\n",
    "    compute__del_z__by__del_bias OR del_z__by__del_b\n",
    "    \n",
    "    As we know that at Z node linear equation would be (In general)\n",
    "    z = np.mdot(weight, X) + b \n",
    "    \n",
    "    Therefore it's differentiation w.r.t bias would be 1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return np.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local__del_z__by__del_bias = compute__del_z__by__del_bias()\n",
    "local__del_z__by__del_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3] Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04800646, -0.03865882])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final__del_cost__by__del_w = np.dot(final__del_cost__by__del_z, local__del_z__by__del_w)\n",
    "final__del_cost__by__del_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lr: Learning rate\n",
    "\"\"\"\n",
    "lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04800646 -0.03865882]\n"
     ]
    }
   ],
   "source": [
    "lr__mul__weights = np.multiply(final__del_cost__by__del_w, 1)\n",
    "print(lr__mul__weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14800646, 0.63865882])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_weights = np.subtract(weights, lr__mul__weights)\n",
    "updated_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.4] Update bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03702352612570836"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "final__del_cost__by__del_bias ($cost/$b)\n",
    "$cost/$b: Change in cost function w.r.t bias\n",
    "\"\"\"\n",
    "final__del_cost__by__del_bias = np.sum(np.multiply( final__del_cost__by__del_z, local__del_z__by__del_bias))\n",
    "final__del_cost__by__del_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03702352612570836"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_bias = bias - np.multiply(lr, final__del_cost__by__del_bias)\n",
    "updated_bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
